<!DOCTYPE html>
<html lang="en">
  <head>
    <link rel="stylesheet" href="0.css" />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Lexend+Tera:wght@100..900&display=swap"
      rel="stylesheet"
    />
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>ShanAI</title>
    <link
      rel="shortcut icon"
      href="https://i.ibb.co/4FVQT2j/eye.png"
      type="image/x-icon"
    />
    <link rel="icon" type="image/x-icon" href="https://i.ibb.co/4FVQT2j/eye.png">
  </head>
  <body>
    <!-- Display project name -->
    <h2 class="omn">SHAN-AI</h2>

    <div id="promptDisplay"></div>

    <!-- Text input box for manual input -->
    <div class="niu1">
      <input
        type="text"
        id="textInput"
        placeholder="Type your prompt here..."
        style="padding: 10px; width: 300px; font-size: 16px"
      />
      <button id="textSubmitBtn">Submit</button>
    </div>

    <!-- Buttons for voice input and stopping -->
    <div class="niu">
      <button id="startBtn">Speak</button>
      <button id="stopBtn">Stop</button>
    </div>

    <!-- Area to display the generated image -->
    <div id="result" style="margin-top: 20px">
      <img id="generatedImage" src="" alt="" />
    </div>

    <!-- Import @google/generative-ai -->
    <script type="importmap">
      {
        "imports": {
          "@google/generative-ai": "https://esm.run/@google/generative-ai"
        }
      }
    </script>

    <script type="module">
      import { GoogleGenerativeAI } from "@google/generative-ai";
      
      const API_KEY = "AIzaSyBhVRbQSns3Ve_pEyO44u9E_6cLFcHWwIU";
      const genAI = new GoogleGenerativeAI(API_KEY);
      const model = genAI.getGenerativeModel({ model: "gemini-1.5-flash" });

      let isSpeaking = false;

      // Function to generate image using the provided prompt
      async function generateImage(prompt) {
        if (!prompt) {
          alert("Please enter a prompt");
          return;
        }

        const API_KEY1 = "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";
        const API_URL1 =
          "https://api-inference.huggingface.co/models/black-forest-labs/FLUX.1-dev";

        try {
          const response = await fetch(API_URL1, {
            method: "POST",
            headers: {
              Authorization: `Bearer ${API_KEY1}`,
              "Content-Type": "application/json",
            },
            body: JSON.stringify({
              inputs: prompt,
              options: {
                wait_for_model: true,
              },
            }),
          });

          if (!response.ok) {
            throw new Error("Failed to generate image");
          }

          const imageBlob = await response.blob();
          const imageUrl = URL.createObjectURL(imageBlob);

          let generatedImageElement = document.getElementById("generatedImage");
          if (generatedImageElement) {
            generatedImageElement.src = imageUrl;
          } else {
            generatedImageElement = document.createElement("img");
            generatedImageElement.id = "generatedImage";
            generatedImageElement.src = imageUrl;
            document
              .getElementById("result")
              .appendChild(generatedImageElement);
          }
        } catch (error) {
          console.error("Error:", error);
          alert("There was an error generating the image.");
        }
      }

      // Updated generateContent function to include image generation
      async function generateContent(prompt) {
        if (isSpeaking) return;

        if (
          prompt.toLowerCase().includes("time") ||
          prompt.toLowerCase().includes("date")
        ) {
          const now = new Date();
          const responseText = `Current date and time is ${now.toLocaleDateString()} ${now.toLocaleTimeString()}.`;
          speak(responseText);
        } else if (prompt.toLowerCase().includes("youtube")) {
          speak("Opening YouTube...");
          window.open("https://www.youtube.com", "_blank");
        } else if (prompt.toLowerCase().includes("google")) {
          speak("Opening Google...");
          window.open("https://www.google.com", "_blank");
        } else if (
          prompt.includes("what is your name") ||
          prompt.includes("who are you")
        ) {
          speak(
            "My name is Shan AI, your voice assistant. I am here to assist you..."
          );
        } else if (prompt.includes("calculator")) {
          speak("Opening Calculator...");
          window.open("Calculator:///");
        } else if (
          prompt.toLowerCase().includes("generate image") ||
          prompt.toLowerCase().includes("create image") ||
          prompt.toLowerCase().includes("create a image") ||
          prompt.toLowerCase().includes("generate a image") ||
          prompt.toLowerCase().includes("give me the image") ||
          prompt.toLowerCase().includes("create picture") ||
          prompt.toLowerCase().includes("create a picture") ||
          prompt.toLowerCase().includes("generate picture") ||
          prompt.toLowerCase().includes("generate a picture") ||
          prompt.toLowerCase().includes("image of")
        ) {
          speak("Generating image...");
          await generateImage(prompt);
        } else {
          try {
            const result = await model.generateContent(prompt, {
              max_tokens: 100,
            });
            const response = await result.response;
            const text = await response.text();
            const filteredText = text.replace(/[#*]/g, "");
            const lines = filteredText.split("\n");
            const speechLineLimit = 15;
            const linesForSpeech = lines.slice(0, speechLineLimit);

            speakLines(linesForSpeech);
          } catch (error) {
            speak("Sorry, I couldn't process your request.");
          }
        }
      }

      function speakLines(lines) {
        if (lines.length === 0) {
          isSpeaking = false;
          return;
        }

        const line = lines.shift();
        document.getElementById("result").innerText = line;

        const utterance = new SpeechSynthesisUtterance(line);
        utterance.rate = 1.2;
        utterance.onend = () => speakLines(lines);
        window.speechSynthesis.speak(utterance);
        isSpeaking = true;
      }

      function speak(text) {
        if (isSpeaking) return;

        isSpeaking = true;
        const utterance = new SpeechSynthesisUtterance(text);
        utterance.rate = 1.2;
        utterance.onend = () => (isSpeaking = false);
        window.speechSynthesis.speak(utterance);
      }

      const SpeechRecognition =
        window.SpeechRecognition || window.webkitSpeechRecognition;
      const recognition = new SpeechRecognition();
      recognition.lang = "en-US";
      recognition.interimResults = false;
      recognition.maxAlternatives = 1;

      recognition.addEventListener("result", (event) => {
        let speechResult = event.results[0][0].transcript;
        speechResult = speechResult.replace(/[+#*]/g, "");
        document.getElementById(
          "promptDisplay"
        ).innerText = `You said: ${speechResult}`;
        generateContent(speechResult);
      });

      document.getElementById("startBtn").addEventListener("click", () => {
        document.getElementById("promptDisplay").innerText = "Listening...";
        recognition.start();
      });

      document.getElementById("stopBtn").addEventListener("click", () => {
        window.speechSynthesis.cancel();
        isSpeaking = false;
        document.getElementById("promptDisplay").innerText = "Stopped";
      });

      document.getElementById("textSubmitBtn").addEventListener("click", () => {
        const userInput = document.getElementById("textInput").value.trim();
        if (userInput) {
          generateContent(userInput);
          document.getElementById("textInput").value = "";
          document.getElementById("promptDisplay").innerText = `You said: ${userInput}`;
        }
      });

      recognition.addEventListener("error", (event) => {
        document.getElementById(
          "promptDisplay"
        ).innerText = `Error occurred: ${event.error}`;
      });

      window.addEventListener("beforeunload", () => {
        window.speechSynthesis.cancel();
        isSpeaking = false;
      });
    </script>
  </body>
</html>
