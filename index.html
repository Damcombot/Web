<html>
  <head>
    <link rel="stylesheet" href="9.css" />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Edu+AU+VIC+WA+NT+Hand:wght@400..700&family=Fira+Sans:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900&family=Space+Grotesk:wght@300..700&family=Syncopate:wght@400;700&display=swap"
      rel="stylesheet"
    />
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Vadarly</title>
    <link
      rel="shortcut icon"
      href="https://i.ibb.co/4FVQT2j/eye.png"
      type="image/x-icon"
    />
  </head>
  <body>
    <!-- Display project name -->
    <h1 id="animated-text">@#%^*~&</h1>

    <!-- Buttons for voice input and stopping -->
    <div class="niu">
      <button id="startBtn">Speak</button>
      <button id="stopBtn">Stop</button>
      <p id="promptDisplay">
        I'm Vadarly, a voice assistant. How may I help you?
      </p>
    </div>
    <video autoplay muted loop id="bg-video">
      <source src="videoplayback.webm" type="video/webm" />
    </video>

    <!-- Video feed for face detection -->
    <video id="camera" autoplay></video>
    <canvas id="canvas"></canvas>

    <!-- Area to display the result -->
    <div id="result" style="margin-top: 20px">
      Tharun | Krishna | Kamal | Sagar | Sachin | Ananjan | Shanjith
    </div>

    <!-- Import @google/generative-ai -->
    <script type="importmap">
      {
        "imports": {
          "@google/generative-ai": "https://esm.run/@google/generative-ai"
        }
      }
    </script>
    <script defer src="https://cdn.jsdelivr.net/npm/face-api.js"></script>
    <script type="module">
      import { GoogleGenerativeAI } from "@google/generative-ai";

      const API_KEY = "AIzaSyBx4K2HYyJN13yXRf01tnDh5dQ-XLpzx_k";
      const genAI = new GoogleGenerativeAI(API_KEY);
      const model = genAI.getGenerativeModel({ model: "gemini-1.5-flash" });

      let isSpeaking = false;

      document.addEventListener("DOMContentLoaded", () => {
        const textElement = document.getElementById("animated-text");
        const text = "VADARLY";
        let index = 0;

        const animateText = () => {
          if (index < text.length) {
            textElement.textContent =
              textElement.textContent.slice(0, index) +
              text[index] +
              textElement.textContent.slice(index + 1);
            index++;
            setTimeout(animateText, 130);
          }
        };

        setTimeout(animateText, 2000);

        // Start face detection
        startFaceDetection();
      });

      async function generateContent(prompt) {
        if (isSpeaking) return;

        if (
          prompt.toLowerCase().includes("time") ||
          prompt.toLowerCase().includes("date")
        ) {
          const now = new Date();
          const responseText = `Current date and time is ${now.toLocaleDateString()} ${now.toLocaleTimeString()}.`;
          document.getElementById("result").innerText = responseText;
          speak(responseText);
        } else if (prompt.toLowerCase().includes("youtube")) {
          window.open("https://www.youtube.com", "_blank");
          speak("Opening youtube...");
        } else if (prompt.toLowerCase().includes("google")) {
          window.open("https://www.google.com", "_blank");
          speak("Opening google...");
        } else if (
          prompt.includes("what is your name") ||
          prompt.includes("who are you")
        ) {
          speak(
            "My name is VADARLY, your voice assistant. I am here to assist you..."
          );
        } else if (prompt.includes("calculator")) {
          window.open("Calculator:///");
          speak("Opening Calculator...");
        } else {
          const result = await model.generateContent(prompt, {
            max_tokens: 100,
          });
          const response = await result.response;
          const text = await response.text();
          const filteredText = text.replace(/[#*]/g, "");
          const lines = filteredText.split("\n");
          const speechLineLimit = 5;
          const linesForSpeech = lines.slice(0, speechLineLimit).join("\n");
          document.getElementById("result").innerText = filteredText;
          speak(linesForSpeech);
        }
      }

      function speak(text) {
        if (isSpeaking) return;

        isSpeaking = true;
        const utterance = new SpeechSynthesisUtterance(text);
        utterance.onend = () => {
          isSpeaking = false;
        };
        window.speechSynthesis.speak(utterance);
      }

      const SpeechRecognition =
        window.SpeechRecognition || window.webkitSpeechRecognition;
      const recognition = new SpeechRecognition();
      recognition.lang = "en-US";
      recognition.interimResults = false;
      recognition.maxAlternatives = 1;

      recognition.addEventListener("result", (event) => {
        let speechResult = event.results[0][0].transcript;
        speechResult = speechResult.replace(/[+#*]/g, "");
        document.getElementById(
          "promptDisplay"
        ).innerText = `You said: ${speechResult}`;
        generateContent(speechResult);
      });

      document.getElementById("startBtn").addEventListener("click", () => {
        document.getElementById("promptDisplay").innerText = "Listening...";
        recognition.start();
      });

      document.getElementById("stopBtn").addEventListener("click", () => {
        window.speechSynthesis.cancel();
        isSpeaking = false;
        document.getElementById("promptDisplay").innerText = "Stopped";
      });

      recognition.addEventListener("error", (event) => {
        document.getElementById(
          "promptDisplay"
        ).innerText = `Error occurred: ${event.error}`;
      });
      // script.js

// Load face-api.js models
async function loadModels() {
    const MODEL_URL = '/models'; // Path to your models directory

    await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);
    await faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL);
    await faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL);
}

// Start video stream and detect faces
async function startVideo() {
    const video = document.getElementById('video');
    const overlay = document.getElementById('overlay');
    const canvas = faceapi.createCanvasFromMedia(video);

    overlay.appendChild(canvas);
    faceapi.matchDimensions(canvas, { width: video.width, height: video.height });

    navigator.mediaDevices.getUserMedia({ video: {} })
        .then(stream => {
            video.srcObject = stream;
        })
        .catch(err => console.error('Error accessing webcam:', err));

    video.addEventListener('play', () => {
        setInterval(async () => {
            const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
                .withFaceLandmarks().withFaceDescriptors();
            const resizedDetections = faceapi.resizeResults(detections, { width: video.width, height: video.height });
            canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);
            faceapi.draw.drawDetections(canvas, resizedDetections);
            faceapi.draw.drawFaceLandmarks(canvas, resizedDetections);
        }, 100);
    });
}

// Initialize
loadModels().then(startVideo);

    </script>
  </body>
</html>
